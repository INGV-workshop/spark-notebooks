{
    "nbformat": 4, 
    "cells": [
        {
            "source": "%AddJar https://repo.eclipse.org/content/repositories/paho-releases/org/eclipse/paho/org.eclipse.paho.client.mqttv3/1.0.2/org.eclipse.paho.client.mqttv3-1.0.2.jar -f\n%AddJar http://central.maven.org/maven2/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar -f\n%AddJar https://github.com/sathipal/spark-streaming-mqtt-with-security_2.10-1.3.0/releases/download/0.0.1/spark-streaming-mqtt-security_2.10-1.3.0-0.0.1.jar -f\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "source": "import org.eclipse.paho.client.mqttv3._\nimport org.apache.spark.SparkContext\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.spark.streaming.mqtt._\nimport org.apache.spark.SparkConf\n\nval ssc = new StreamingContext(sc.asInstanceOf[SparkContext], Seconds(1))\n\nval lines = MQTTUtils.createStream(ssc, // Spark Streaming Context\n\"ssl://3etv6p.messaging.internetofthings.ibmcloud.com:8883\", // Watson IoT Platform URL\n\"iot-2/type/+/id/+/evt/+/fmt/+\", // MQTT topic to receive the events\n\"a:3etv6p:random\", // Unique ID of the application\n\"a-3etv6p-7icb4uf5fh\", // API-Key\n\"wgbXafCw*!eR3x?lDm\") // Auth-Token\n\nimport java.util.Map.Entry\nimport com.google.gson.JsonElement\nimport com.google.gson.JsonParser\nimport java.util.Set\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "source": "val deviceMappedLines = lines.map(x => ((x.split(\" \", 2)(0)).split(\"/\")(4), x.split(\" \", 2)(1)))\n\n// Map the Json payload into scala map\nval jsonLines = deviceMappedLines.map(x => {\n var dataMap:scala.collection.mutable.Map[String, Any] = scala.collection.mutable.Map()\n val payload = new JsonParser().parse(x._2).getAsJsonObject()\n var deviceObject = payload\n val setObj = deviceObject.entrySet()\n val itr = setObj.iterator()\n while(itr.hasNext()) {\n val entry = itr.next();\n try {\n dataMap.put(entry.getKey(), entry.getValue().getAsDouble())\n } catch {\n case e: Exception => dataMap.put(entry.getKey(), entry.getValue().getAsString())\n }\n }\n (x._1, dataMap)\n})", 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "source": "/**\n * Create a simple threshold rule. If cpu usage is greater than 10, alert\n */\n \n val threasholdCrossedLines = jsonLines.filter(\n x => {\n var status = false;\n val lat = x._2.get(\"latitude\")\n val lon = x._2.get(\"longitude\")\n if(lat != null && lon != null) {\n\t /* example */\n if(lat.get.asInstanceOf[Double] > 41.90 && lon.get.asInstanceOf[Double] > 12.50) {\n status = true\n }\n }\n status\n })\n\nthreasholdCrossedLines.print()\n\nssc.start()\nssc.awaitTermination()", 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": null, 
            "outputs": []
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": null, 
            "outputs": []
        }
    ], 
    "metadata": {
        "language_info": {
            "pygments_lexer": "scala", 
            "mimetype": "text/x-scala", 
            "name": "scala", 
            "file_extension": ".scala", 
            "codemirror_mode": "text/x-scala", 
            "version": "2.11.8"
        }, 
        "kernelspec": {
            "language": "scala", 
            "display_name": "Scala 2.11 with Spark 2.1", 
            "name": "scala-spark21"
        }
    }, 
    "nbformat_minor": 1
}